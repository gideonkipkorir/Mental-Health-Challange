{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libriaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>I feel that it was better I dieAm happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>Why do I get hallucinations?</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>I am stresseed due to lack of financial suppor...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>Why is life important?</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>How could I be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            I feel that it was better I dieAm happy  Depression\n",
       "1  9JDAGUV3                       Why do I get hallucinations?       Drugs\n",
       "2  419WR1LQ  I am stresseed due to lack of financial suppor...  Depression\n",
       "3  6UY7DX6Q                             Why is life important?     Suicide\n",
       "4  FYC0FTFB  How could I be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Gideon Kipkorir\\Desktop\\colab\\Datasets\\Train (4).csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r'C:\\Users\\Gideon Kipkorir\\Desktop\\colab\\Datasets\\Test (3).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (616, 3)\n",
      "test sahpe: (309, 2)\n"
     ]
    }
   ],
   "source": [
    "print('train shape:',train.shape)\n",
    "print('test sahpe:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 616 entries, 0 to 615\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      616 non-null    object\n",
      " 1   text    616 non-null    object\n",
      " 2   label   616 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 14.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING texts to get rid of punctuation\n",
    "# train.text = train.text.str.replace('[^a-zA-Z0-9]', ' ')\n",
    "# train.text = train['text'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9736J4UE</td>\n",
       "      <td>Why is everything so hard to deal with in this...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>AAKPNVQO</td>\n",
       "      <td>I am broke and very  unpreparedness in exams</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>NM3JOH4T</td>\n",
       "      <td>I feel so low sickly,I was lonelyCurrently fee...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>NOXKH5TS</td>\n",
       "      <td>Whom will I approach when mentally disturbed?</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>KWNGKGHQ</td>\n",
       "      <td>I feel like life does not make sense</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1IHTBDJ2</td>\n",
       "      <td>What can I do to be relieved?</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>S6WK4NBL</td>\n",
       "      <td>I feel confused, how can  I overcome the problem?</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>4EHEFJ7J</td>\n",
       "      <td>How can I forgive myself from the past?</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               text       label\n",
       "6    9736J4UE  Why is everything so hard to deal with in this...  Depression\n",
       "252  AAKPNVQO       I am broke and very  unpreparedness in exams  Depression\n",
       "358  NM3JOH4T  I feel so low sickly,I was lonelyCurrently fee...  Depression\n",
       "246  NOXKH5TS      Whom will I approach when mentally disturbed?  Depression\n",
       "302  KWNGKGHQ               I feel like life does not make sense  Depression\n",
       "298  1IHTBDJ2                      What can I do to be relieved?  Depression\n",
       "603  S6WK4NBL  I feel confused, how can  I overcome the problem?  Depression\n",
       "583  4EHEFJ7J            How can I forgive myself from the past?  Depression"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23704366d08>"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= train.label, data = train  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depression cases are 352\n",
      "Drug cases are 58\n",
      "sucide cases are 66\n",
      "Alchohol cases are 140\n"
     ]
    }
   ],
   "source": [
    "df_drugs = train[train.label=='Drugs']\n",
    "df_depression = train[train.label == 'Depression']\n",
    "df_suicide = train[train.label =='Suicide']\n",
    "df_alcohol = train[train.label == 'Alcohol']\n",
    "print('depression cases are {}'.format(len(df_depression)))\n",
    "print('Drug cases are {}'.format(len(df_drugs)))\n",
    "print('sucide cases are {}'.format(len(df_suicide)))\n",
    "print('Alchohol cases are {}'.format(len(df_alcohol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.label = train.label.replace({'Drugs':1, 'Depression':2, 'Suicide':3, 'Alcohol':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dataset is so imbalance am going to try and sample them equally\n",
    "depression_sample = df_depression.sample(80) #sampling 80 texts\n",
    "alcohol_sample = df_alcohol.sample(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_df = pd.concat([depression_sample, alcohol_sample, df_suicide, df_drugs], axis = 0)\n",
    "balance_df = balance_df.sample(frac=1).reset_index(drop=True)#shaffling the data\n",
    "balance_df.label = balance_df.label.replace({'Drugs':1, 'Depression':2, 'Suicide':3, 'Alcohol':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2QRTGS6A</td>\n",
       "      <td>Why I needed to keep holding on to nothing. If...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1M6N5OI2</td>\n",
       "      <td>How to stop the addiction?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4AEMAVSI</td>\n",
       "      <td>Why is alcohol sold along the school perimeter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S6Z4BOS6</td>\n",
       "      <td>My hustle is not picking up</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5JLVKXY3</td>\n",
       "      <td>I am involved in a Love affair and I would lik...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text  label\n",
       "0  2QRTGS6A  Why I needed to keep holding on to nothing. If...      3\n",
       "1  1M6N5OI2                         How to stop the addiction?      4\n",
       "2  4AEMAVSI    Why is alcohol sold along the school perimeter       4\n",
       "3  S6Z4BOS6                        My hustle is not picking up      2\n",
       "4  5JLVKXY3  I am involved in a Love affair and I would lik...      2"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 3)"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_df = balance_df.drop(['ID'],1)\n",
    "test_texts = test.drop(['ID'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_texts['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = balance_df.text\n",
    "train_labels = LabelEncoder().fit_transform(balance_df.label)\n",
    "comb = pd.concat([train_texts, test_texts],axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284,)\n",
      "(309,)\n"
     ]
    }
   ],
   "source": [
    "print(train_texts.shape)\n",
    "print(test_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df: remove the words from the vocabulary which have occurred in less than ‘min_df’ number of files.\n",
    "max_df: remove the words from the vocabulary which have occurred in more than _‘maxdf’ * total number of files in corpus.\n",
    "sublinear_tf: set to True to scale the term frequency in logarithmic scale.\n",
    "stop_words: remove the predefined stop words in 'english'.\n",
    "use_idf: weight factor must use inverse document frequency.\n",
    "ngram_range: (1, 2) to indicate that unigrams and bigrams will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')\n",
    "features = tfidf.fit_transform(comb).toarray()\n",
    "# test_texts = tfidf.fit_transform(test_texts)\n",
    "# print(\"Each of the %d text is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 104)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "# print(test_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb = pd.concat([features, test_texts],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP_K = 20000\n",
    "# # selector = SelectKBest(f_classif, k=min(TOP_K, train_texts[]))\n",
    "# # selector.fit(train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features[0:284], train_labels, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = ensemble.GradientBoostingClassifier(n_estimators= 300, max_depth=3, learning_rate= 0.1)\n",
    "xgb = xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  1  3  0]\n",
      " [ 0  9  6  0]\n",
      " [ 0  1  8  0]\n",
      " [ 0  1  2 12]]\n",
      "0.7543859649122807\n",
      "0.7543859649122807\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(xgb,features[0:284], train_labels, cv = 10,scoring = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771551724137931"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Depression', 'Drugs', 'Suicide', 'Alcohol'], dtype=object)"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb.predict(features[285:])\n",
    "Drugs = []\n",
    "Depression =[]\n",
    "Suicide=[]\n",
    "Alcohol = []\n",
    "for value in pred:\n",
    "    if value ==1:\n",
    "        Drugs.append(1)\n",
    "    elif value < 0:\n",
    "        Drugs.append(0)\n",
    "#     elif value ==2:\n",
    "#         Depression.append(1)\n",
    "#     elif value ==3:\n",
    "#         Suicide.append(1)\n",
    "#     elif value ==0:\n",
    "#         Alcohol.append(1)\n",
    "#     else:\n",
    "#         Drugs.append(0)\n",
    "#         Alcohol.append(0)\n",
    "#         Suicide.append(0)\n",
    "#         Depression.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Drugs)\n",
    "# # max(Depression)\n",
    "# len(Suicide)\n",
    "# len(Alcohol)\n",
    "# # len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0EPULUM5</td>\n",
       "      <td>Alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GM4C5GD</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID      labels\n",
       "0  02V56KMO       Drugs\n",
       "1  03BMGTOK       Drugs\n",
       "2  03LZVFM6       Drugs\n",
       "3  0EPULUM5     Alcohol\n",
       "4  0GM4C5GD  Depression"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame( pred, columns=['labels'])\n",
    "# submit['Drugs'] = Drugs\n",
    "# submit['Suicide'] = Suicide\n",
    "submit['ID'] = test.ID\n",
    "submit = submit[['ID','labels']] \n",
    "submit.labels= submit.labels.replace({1:'Drugs', 2:'Depression',3:'Suicide', 0:'Alcohol'})\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-786-6bec6562e666>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-786-6bec6562e666>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    sub.to_csv(C:\\Users\\Gideon Kipkorir\\Desktop\\colab\\Datasets\\'submission.csv')\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame(pd.get_dummies(submit.labels))\n",
    "sub['ID'] = test.ID\n",
    "sub = sub[['ID','Depression','Alcohol', 'Suicide','Drugs']]\n",
    "sub.head()\n",
    "sub.to_csv(C:\\Users\\Gideon Kipkorir\\Desktop\\colab\\Datasets\\'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[['Depression','Alcohol', 'Drugs', 'Suicide']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.Label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization parameters\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, test_texts):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(test_texts.text)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(test_texts.text).astype('float32')\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [227, 284]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-c26d8cfdfd7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mselector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTOP_K\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \"\"\"\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [227, 284]"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "selector.fit(x_train, train_labels)\n",
    "x_train = selector.transform(x_train).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-c10796fea2cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         \"\"\"\n\u001b[0;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1859\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1235\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m                 raise ValueError(\n\u001b[1;32m-> 1237\u001b[1;33m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0m\u001b[0;32m   1238\u001b[0m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0;32m   1239\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "tfidf.fit_transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.fit(x_train, train_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(vectorizer.transform(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.30110851])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
